{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1uSc8be8e1nXBX8LEAmkH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MGhimiray/Python-libraries/blob/main/scikit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required modules and the iris data set"
      ],
      "metadata": {
        "id": "dobotjqRwhBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "\n",
        "print(\"Features:\", iris.feature_names)           #column name\n",
        "print(\"Target Labels:\", iris.target_names)        #species name\n",
        "print(\"Data Shape:\", iris.data.shape)         # data shape\n",
        "\n",
        "print(\"First 5 Samples:\")\n",
        "for i in range(5):\n",
        "    print(i, \": Features=\", iris.data[i], \"Target=\", iris.target[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "Th4ustRFCYwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data into train data set and test data set"
      ],
      "metadata": {
        "id": "EvpjBaZ6xud9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=30)\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "Qf0k1EJxEVTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using KNN model, training the model, verifying the results"
      ],
      "metadata": {
        "id": "19TrqIMCx2tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = sum(y_pred == y_test) / len(y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"  Prediction   |   Test   |  Target Name  |  Predicted Name\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "for i in range(len(y_pred)):\n",
        "    prediction = y_pred[i]\n",
        "    test = y_test[i]\n",
        "    target_name = iris.target_names[test]\n",
        "    prediction_name = iris.target_names[y_pred[i]]\n",
        "    print(\"{:^8} | {:^8} | {:^13} | {:^14}\".format(prediction, test, target_name, prediction_name))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zce3dG8Js92A",
        "outputId": "85a157f9-d972-445c-db86-9fbd847c8ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9333333333333333\n",
            "  Prediction   |   Test   |  Target Name  |  Predicted Name\n",
            "----------------------------------------------------------\n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   2     |    2     |   virginica   |   virginica   \n",
            "   1     |    1     |  versicolor   |   versicolor  \n",
            "   1     |    1     |  versicolor   |   versicolor  \n",
            "   2     |    2     |   virginica   |   virginica   \n",
            "   2     |    2     |   virginica   |   virginica   \n",
            "   1     |    1     |  versicolor   |   versicolor  \n",
            "   2     |    2     |   virginica   |   virginica   \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   2     |    2     |   virginica   |   virginica   \n",
            "   1     |    1     |  versicolor   |   versicolor  \n",
            "   1     |    1     |  versicolor   |   versicolor  \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   1     |    1     |  versicolor   |   versicolor  \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   2     |    1     |  versicolor   |   virginica   \n",
            "   2     |    2     |   virginica   |   virginica   \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   2     |    2     |   virginica   |   virginica   \n",
            "   2     |    2     |   virginica   |   virginica   \n",
            "   2     |    1     |  versicolor   |   virginica   \n",
            "   2     |    2     |   virginica   |   virginica   \n",
            "   0     |    0     |    setosa     |     setosa    \n",
            "   1     |    1     |  versicolor   |   versicolor  \n"
          ]
        }
      ]
    }
  ]
}